{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fca4ac70",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from typing import List, Tuple, Dict\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "import copy          \n",
    "import math\n",
    "import itertools\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import csv\n",
    "import os\n",
    "import sys, io, os, textwrap\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SewerLink:\n",
    "    \"\"\"Represents a sewer link with its properties\"\"\"\n",
    "    up_node: int\n",
    "    down_node: int\n",
    "    length: float\n",
    "    diameter: float = 0.2  # meters\n",
    "    slope: float = 0.001  # 1 in 1000\n",
    "    flow: float = 0.0  # m3/s\n",
    "    \n",
    "@dataclass\n",
    "class Node:\n",
    "    \"\"\"Represents a manhole node\"\"\"\n",
    "    id: int\n",
    "    wastewater_contribution: float  # l/s\n",
    "    ground_level: float = 0.0\n",
    "    invert_level: float = 0.0\n",
    "\n",
    "class SpanningTreeGenerator:\n",
    "    \"\"\"Generates predetermined number of spanning trees in order of increasing length\"\"\"\n",
    "    \n",
    "    def __init__(self, base_graph: nx.Graph, outlet_node: int):\n",
    "        self.base_graph = base_graph\n",
    "        self.outlet_node = outlet_node\n",
    "        self.spanning_trees = []\n",
    "        \n",
    "    def generate_spanning_trees(self, n_trees: int) -> List[nx.Graph]:\n",
    "        \"\"\"Generate n spanning trees in order of increasing total length\"\"\"\n",
    "        all_trees = []\n",
    "        seen_trees = set()\n",
    "        \n",
    "        # Generate MST as first tree\n",
    "        mst = nx.minimum_spanning_tree(self.base_graph, weight='length')\n",
    "        tree_signature = self._get_tree_signature(mst)\n",
    "        all_trees.append((self._calculate_total_length(mst), mst))\n",
    "        seen_trees.add(tree_signature)\n",
    "        \n",
    "        print(f\"Generated MST with length: {self._calculate_total_length(mst):.2f} m\")\n",
    "        \n",
    "        # Generate additional trees using different methods\n",
    "        attempts = 0\n",
    "        max_attempts = n_trees * 100\n",
    "        \n",
    "        while len(all_trees) < n_trees and attempts < max_attempts:\n",
    "            attempts += 1\n",
    "            \n",
    "            # Method 1: Random spanning tree using DFS\n",
    "            if attempts % 3 == 0:\n",
    "                tree = self._random_spanning_tree_dfs()\n",
    "            # Method 2: Modified Kruskal with randomization\n",
    "            elif attempts % 3 == 1:\n",
    "                tree = self._random_spanning_tree_kruskal()\n",
    "            # Method 3: Random walk based\n",
    "            else:\n",
    "                tree = self._random_spanning_tree_walk()\n",
    "            \n",
    "            if tree and nx.is_connected(tree) and tree.number_of_nodes() == self.base_graph.number_of_nodes():\n",
    "                tree_signature = self._get_tree_signature(tree)\n",
    "                if tree_signature not in seen_trees:\n",
    "                    length = self._calculate_total_length(tree)\n",
    "                    all_trees.append((length, tree))\n",
    "                    seen_trees.add(tree_signature)\n",
    "                    if len(all_trees) % 5 == 0:\n",
    "                        print(f\"Generated {len(all_trees)} trees...\")\n",
    "        \n",
    "        # Sort by length and return top n_trees\n",
    "        all_trees.sort(key=lambda x: x[0])\n",
    "        self.spanning_trees = [tree for _, tree in all_trees[:n_trees]]\n",
    "        \n",
    "        print(f\"Successfully generated {len(self.spanning_trees)} unique spanning trees\")\n",
    "        return self.spanning_trees\n",
    "    \n",
    "    def _random_spanning_tree_dfs(self) -> nx.Graph:\n",
    "        \"\"\"Generate random spanning tree using randomized DFS\"\"\"\n",
    "        tree = nx.Graph()\n",
    "        tree.add_nodes_from(self.base_graph.nodes(data=True))\n",
    "        \n",
    "        visited = set()\n",
    "        stack = [self.outlet_node]\n",
    "        visited.add(self.outlet_node)\n",
    "        \n",
    "        while stack and len(visited) < self.base_graph.number_of_nodes():\n",
    "            current = stack.pop()\n",
    "            neighbors = list(self.base_graph.neighbors(current))\n",
    "            np.random.shuffle(neighbors)\n",
    "            \n",
    "            for neighbor in neighbors:\n",
    "                if neighbor not in visited:\n",
    "                    tree.add_edge(current, neighbor, **self.base_graph[current][neighbor])\n",
    "                    visited.add(neighbor)\n",
    "                    stack.append(neighbor)\n",
    "        \n",
    "        return tree if len(visited) == self.base_graph.number_of_nodes() else None\n",
    "    \n",
    "    def _random_spanning_tree_kruskal(self) -> nx.Graph:\n",
    "        \"\"\"Generate spanning tree using randomized Kruskal's algorithm\"\"\"\n",
    "        edges = list(self.base_graph.edges(data=True))\n",
    "        # Randomize edge weights slightly\n",
    "        weighted_edges = [(u, v, data['length'] * (0.8 + 0.4 * np.random.random()), data) \n",
    "                         for u, v, data in edges]\n",
    "        weighted_edges.sort(key=lambda x: x[2])\n",
    "        \n",
    "        tree = nx.Graph()\n",
    "        tree.add_nodes_from(self.base_graph.nodes(data=True))\n",
    "        \n",
    "        for u, v, _, data in weighted_edges:\n",
    "            tree.add_edge(u, v, **data)\n",
    "            if not nx.is_tree(tree):\n",
    "                tree.remove_edge(u, v)\n",
    "            if tree.number_of_edges() == self.base_graph.number_of_nodes() - 1:\n",
    "                break\n",
    "        \n",
    "        return tree if nx.is_connected(tree) else None\n",
    "    \n",
    "    def _random_spanning_tree_walk(self) -> nx.Graph:\n",
    "        \"\"\"Generate spanning tree using random walk\"\"\"\n",
    "        tree = nx.Graph()\n",
    "        tree.add_nodes_from(self.base_graph.nodes(data=True))\n",
    "        \n",
    "        visited = set()\n",
    "        start_node = np.random.choice(list(self.base_graph.nodes()))\n",
    "        visited.add(start_node)\n",
    "        \n",
    "        while len(visited) < self.base_graph.number_of_nodes():\n",
    "            # Pick a random visited node\n",
    "            current = np.random.choice(list(visited))\n",
    "            # Get unvisited neighbors\n",
    "            neighbors = [n for n in self.base_graph.neighbors(current) if n not in visited]\n",
    "            \n",
    "            if neighbors:\n",
    "                next_node = np.random.choice(neighbors)\n",
    "                tree.add_edge(current, next_node, **self.base_graph[current][next_node])\n",
    "                visited.add(next_node)\n",
    "            \n",
    "        return tree if nx.is_connected(tree) else None\n",
    "    \n",
    "    def _get_tree_signature(self, tree: nx.Graph) -> frozenset:\n",
    "        \"\"\"Get unique signature for a tree based on its edges\"\"\"\n",
    "        return frozenset(frozenset([u, v]) for u, v in tree.edges())\n",
    "    \n",
    "    def _calculate_total_length(self, graph: nx.Graph) -> float:\n",
    "        \"\"\"Calculate total length of all edges\"\"\"\n",
    "        return sum(data['length'] for _, _, data in graph.edges(data=True))\n",
    "\n",
    "class SewerHydraulics:\n",
    "    \n",
    "    \"\"\"Calculate sewer hydraulic parameters\"\"\"\n",
    "    \n",
    "    def __init__(self, manning_n: float = 0.013):\n",
    "        self.n = manning_n\n",
    "        \n",
    "    def calculate_flow_parameters(self, Q: float, D: float, S: float) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate hydraulic parameters for partially full circular sewer\n",
    "        Q: discharge (m3/s)\n",
    "        D: diameter (m)\n",
    "        S: slope (dimensionless)\n",
    "        \n",
    "        Returns None if parameters are invalid or calculation fails\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Input validation\n",
    "            if Q is None or D is None or S is None:\n",
    "                return None\n",
    "            \n",
    "            # Check for zero or negative values\n",
    "            if Q <= 0:\n",
    "                return None  # Zero or negative discharge\n",
    "            \n",
    "            if D <= 0:\n",
    "                return None  # Invalid diameter\n",
    "            \n",
    "            if S <= 0:\n",
    "                return None  # Invalid slope\n",
    "            \n",
    "            if self.n <= 0:\n",
    "                return None  # Invalid Manning's n\n",
    "            \n",
    "            # Equation 3: K = Q*n*D^(-8/3)*S^(-1/2)\n",
    "            try:\n",
    "                K = Q * self.n * (D ** (-8/3)) * (S ** (-0.5))\n",
    "            except (ZeroDivisionError, ValueError, OverflowError):\n",
    "                return None\n",
    "            \n",
    "            # Check for invalid K values\n",
    "            if not np.isfinite(K) or K <= 0:\n",
    "                return None\n",
    "            \n",
    "            # Ensure K < 1/Ï€ (constraint from equation 4)\n",
    "            if K >= 1/np.pi:\n",
    "                return None\n",
    "            \n",
    "            # Equation 4: Calculate Î¸\n",
    "            try:\n",
    "                inner_sqrt = np.sqrt(np.pi * K)\n",
    "                if inner_sqrt > 1:  # Check domain for next sqrt\n",
    "                    return None\n",
    "                \n",
    "                middle_sqrt = np.sqrt(1 - inner_sqrt)\n",
    "                if middle_sqrt > 1:  # Check domain for final sqrt\n",
    "                    return None\n",
    "                \n",
    "                outer_sqrt = np.sqrt(1 - middle_sqrt)\n",
    "                theta = (3 * np.pi / 2) * outer_sqrt\n",
    "                \n",
    "            except (ValueError, RuntimeWarning):\n",
    "                return None\n",
    "            \n",
    "            # Validate theta\n",
    "            if not np.isfinite(theta) or theta <= 0 or theta > 2 * np.pi:\n",
    "                return None\n",
    "            \n",
    "            # Equation 5: d/D ratio\n",
    "            try:\n",
    "                d_D = 0.5 * (1 - np.cos(theta / 2))\n",
    "            except (ValueError, OverflowError):\n",
    "                return None\n",
    "            \n",
    "            # Validate d/D ratio\n",
    "            if not np.isfinite(d_D) or d_D < 0 or d_D > 1:\n",
    "                return None\n",
    "            \n",
    "            # Equation 6: hydraulic radius\n",
    "            try:\n",
    "                sin_theta = np.sin(theta)\n",
    "                if not np.isfinite(sin_theta):\n",
    "                    return None\n",
    "                \n",
    "                r = (D / 4) * ((theta - sin_theta) / theta)\n",
    "            except (ZeroDivisionError, ValueError, OverflowError):\n",
    "                return None\n",
    "            \n",
    "            # Validate hydraulic radius\n",
    "            if not np.isfinite(r) or r <= 0 or r > D:\n",
    "                return None\n",
    "            \n",
    "            # Calculate velocity: V = (1/n) * R^(2/3) * S^(1/2)\n",
    "            try:\n",
    "                V = (1 / self.n) * (r ** (2/3)) * (S ** 0.5)\n",
    "            except (ZeroDivisionError, ValueError, OverflowError):\n",
    "                return None\n",
    "            \n",
    "            # Validate velocity\n",
    "            if not np.isfinite(V) or V <= 0:\n",
    "                return None\n",
    "            \n",
    "            # Calculate flow depth\n",
    "            d = d_D * D\n",
    "            if not np.isfinite(d) or d < 0 or d > D:\n",
    "                return None\n",
    "            \n",
    "            # All calculations successful, return results\n",
    "            return {\n",
    "                'K': K,\n",
    "                'theta': theta,\n",
    "                'd_D': d_D,\n",
    "                'r': r,\n",
    "                'V': V,\n",
    "                'd': d\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            # Catch any unexpected errors\n",
    "            # print(f\"Warning: Hydraulic calculation failed: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "class CostCalculator:\n",
    "    \"\"\"Calculate costs for sewer network components\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Extended cost data with larger diameters\n",
    "        self.pipe_costs = {\n",
    "            0.2: 518, 0.25: 724, 0.3: 973, 0.35: 1600,\n",
    "            0.4: 1850, 0.45: 2150, 0.5: 2520, 0.6: 2600, \n",
    "            0.7: 2900, 0.8: 3500, 0.9: 4000, 1.0: 5000, \n",
    "            1.5: 10000\n",
    "        }\n",
    "        \n",
    "        self.manhole_costs = {\n",
    "            (0, 1): 11800, (1, 2): 23100, (2, 3): 40000,\n",
    "            (3, 4): 54600, (4, 5): 69200, (5, 6): 77500\n",
    "        }\n",
    "        \n",
    "        self.earthwork_costs = {\n",
    "            (0, 1.5): 203, (1.5, 3.0): 233.5,\n",
    "            (3.0, 4.5): 299, (4.5, 6.0): 405\n",
    "        }\n",
    "        \n",
    "    def get_pipe_cost(self, diameter: float, length: float) -> float:\n",
    "        \"\"\"Get cost per meter for pipe diameter\"\"\"\n",
    "        available_diameters = sorted(self.pipe_costs.keys())\n",
    "        selected_d = min(available_diameters, key=lambda x: abs(x - diameter))\n",
    "        if selected_d < diameter:\n",
    "            idx = available_diameters.index(selected_d)\n",
    "            if idx < len(available_diameters) - 1:\n",
    "                selected_d = available_diameters[idx + 1]\n",
    "        return self.pipe_costs[selected_d] * length\n",
    "    \n",
    "    def get_manhole_cost(self, depth: float) -> float:\n",
    "        \"\"\"Get manhole cost based on depth\"\"\"\n",
    "        for (d_min, d_max), cost in self.manhole_costs.items():\n",
    "            if d_min < depth <= d_max:\n",
    "                return cost\n",
    "        return 77500  # Maximum cost\n",
    "    \n",
    "    def get_earthwork_cost(self, depth: float, volume: float) -> float:\n",
    "        \"\"\"Get earthwork cost\"\"\"\n",
    "        for (d_min, d_max), cost in self.earthwork_costs.items():\n",
    "            if d_min < depth <= d_max:\n",
    "                return cost * volume\n",
    "        return 405 * volume  # Maximum cost\n",
    "    \n",
    "    \n",
    "\n",
    "class ModifiedPSO:\n",
    "    \"\"\"Modified Particle Swarm Optimization for sewer component sizing\"\"\"\n",
    "    \n",
    "    def __init__(self, n_particles: int, n_iterations: int, n_dimensions: int):\n",
    "        self.n_particles = n_particles\n",
    "        self.n_iterations = n_iterations\n",
    "        self.n_dimensions = n_dimensions\n",
    "        \n",
    "        # PSO parameters\n",
    "        self.w_max = 0.7\n",
    "        self.w_min = 0.2\n",
    "        self.c1_max = 2.0\n",
    "        self.c1_min = 0.5\n",
    "        self.c2_max = 2.0\n",
    "        self.c2_min = 0.5\n",
    "        \n",
    "        # Initialize particles\n",
    "        self.particles = None\n",
    "        self.velocities = None\n",
    "        self.pbest = None\n",
    "        self.pbest_costs = None\n",
    "        self.gbest = None\n",
    "        self.gbest_cost = float('inf')\n",
    "        \n",
    "    def optimize(self, cost_function, bounds: List[Tuple[float, float]]) -> Tuple:\n",
    "        \"\"\"\n",
    "        Optimize using Modified PSO\n",
    "        cost_function: function to minimize\n",
    "        bounds: list of (min, max) for each dimension\n",
    "        \"\"\"\n",
    "        # Initialize particles randomly within bounds\n",
    "        self.particles = np.random.uniform(\n",
    "            low=[b[0] for b in bounds],\n",
    "            high=[b[1] for b in bounds],\n",
    "            size=(self.n_particles, self.n_dimensions)\n",
    "        )\n",
    "        \n",
    "        # Initialize velocities\n",
    "        v_max = [(b[1] - b[0]) * 0.15 for b in bounds]\n",
    "        self.velocities = np.random.uniform(\n",
    "            low=[-vm for vm in v_max],\n",
    "            high=v_max,\n",
    "            size=(self.n_particles, self.n_dimensions)\n",
    "        )\n",
    "        \n",
    "        # Initialize personal best\n",
    "        self.pbest = self.particles.copy()\n",
    "        self.pbest_costs = np.array([cost_function(p) for p in self.particles])\n",
    "        \n",
    "        # Initialize global best\n",
    "        best_idx = np.argmin(self.pbest_costs)\n",
    "        self.gbest = self.pbest[best_idx].copy()\n",
    "        self.gbest_cost = self.pbest_costs[best_idx]\n",
    "        \n",
    "        # Optimization loop\n",
    "        for t in range(self.n_iterations):\n",
    "            # Update inertia weight and acceleration coefficients (Eqs 20-22)\n",
    "            w = self.w_max - (self.w_max - self.w_min) * t / self.n_iterations\n",
    "            c1 = self.c1_max - (self.c1_max - self.c1_min) * t / self.n_iterations\n",
    "            c2 = self.c2_max - (self.c2_max - self.c2_min) * t / self.n_iterations\n",
    "            \n",
    "            for i in range(self.n_particles):\n",
    "                # Random coefficients\n",
    "                r1 = np.random.random(self.n_dimensions)\n",
    "                r2 = np.random.random(self.n_dimensions)\n",
    "                \n",
    "                # Update velocity (Eq 19)\n",
    "                self.velocities[i] = (\n",
    "                    w * self.velocities[i] +\n",
    "                    c1 * r1 * (self.pbest[i] - self.particles[i]) +\n",
    "                    c2 * r2 * (self.gbest - self.particles[i])\n",
    "                )\n",
    "                \n",
    "                # Limit velocity\n",
    "                for d in range(self.n_dimensions):\n",
    "                    self.velocities[i, d] = np.clip(\n",
    "                        self.velocities[i, d],\n",
    "                        -v_max[d], v_max[d]\n",
    "                    )\n",
    "                \n",
    "                # Update position (Eq 18)\n",
    "                self.particles[i] = self.particles[i] + self.velocities[i]\n",
    "                \n",
    "                # Apply bounds\n",
    "                for d in range(self.n_dimensions):\n",
    "                    self.particles[i, d] = np.clip(\n",
    "                        self.particles[i, d],\n",
    "                        bounds[d][0], bounds[d][1]\n",
    "                    )\n",
    "                \n",
    "                # Evaluate fitness\n",
    "                cost = cost_function(self.particles[i])\n",
    "                \n",
    "                # Update personal best\n",
    "                if cost < self.pbest_costs[i]:\n",
    "                    self.pbest[i] = self.particles[i].copy()\n",
    "                    self.pbest_costs[i] = cost\n",
    "                    \n",
    "                    # Update global best\n",
    "                    if cost < self.gbest_cost:\n",
    "                        self.gbest = self.particles[i].copy()\n",
    "                        self.gbest_cost = cost\n",
    "            \n",
    "            if (t + 1) % 10 == 0:\n",
    "                print(f\"Iteration {t+1}/{self.n_iterations}, Best Cost: {self.gbest_cost:.2f}\")\n",
    "        \n",
    "        return self.gbest, self.gbest_cost\n",
    "\n",
    "    \n",
    "    \n",
    "class SewerNetworkOptimizer:\n",
    "    \"\"\"Main optimizer combining spanning tree generation and PSO\"\"\"\n",
    "    \n",
    "    def __init__(self, base_graph: nx.Graph, nodes: Dict[int, Node], outlet_node: int):\n",
    "        self.base_graph = base_graph\n",
    "        self.nodes = nodes\n",
    "        self.outlet_node = outlet_node\n",
    "        self.hydraulics = SewerHydraulics()\n",
    "        self.cost_calc = CostCalculator()\n",
    "        self.best_design_details = None  # Store detailed design info\n",
    "        self.optimization_history = {}  # Store optimization results for plotting\n",
    "        \n",
    "    def calculate_cumulative_flow(self, tree: nx.Graph) -> float:\n",
    "        \"\"\"Calculate total cumulative flow (CQ) for a layout (Eq 1)\"\"\"\n",
    "        # Convert to directed tree first\n",
    "        directed_tree = self._get_flow_direction_tree(tree)\n",
    "        \n",
    "        total_cq = 0.0\n",
    "        \n",
    "        # For each link, calculate the flow and add to cumulative total\n",
    "        for u, v in directed_tree.edges():\n",
    "            # Calculate flow in this link by summing all upstream contributions\n",
    "            link_flow = self._calculate_link_flow_directed(directed_tree, u, v)\n",
    "            total_cq += link_flow\n",
    "        \n",
    "        return total_cq\n",
    "    \n",
    "    def _calculate_link_flow(self, tree: nx.Graph, u: int, v: int) -> float:\n",
    "        \"\"\"Calculate flow in a link by summing upstream contributions (simplified)\"\"\"\n",
    "        # This is a fallback for undirected trees\n",
    "        return abs(self.nodes[u].wastewater_contribution + \n",
    "                   self.nodes[v].wastewater_contribution) / 1000  # Convert l/s to m3/s\n",
    "    \n",
    "    def optimize_layout_sequence(self, n_layouts: int = 10, \n",
    "                                 pso_particles: int = 100,\n",
    "                                 pso_iterations: int = 30):\n",
    "        \"\"\"Main optimization routine\"\"\"\n",
    "        # Step 1: Generate spanning trees\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 1: Generating Spanning Trees\")\n",
    "        print(\"=\" * 80)\n",
    "        tree_gen = SpanningTreeGenerator(self.base_graph, self.outlet_node)\n",
    "        trees = tree_gen.generate_spanning_trees(n_layouts)\n",
    "        \n",
    "        if len(trees) < n_layouts:\n",
    "            print(f\"âš  Warning: Only generated {len(trees)} unique trees out of {n_layouts} requested\")\n",
    "        \n",
    "        # Step 2: Calculate CQ for each layout\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 2: Calculating Cumulative Flows (CQ)\")\n",
    "        print(\"=\" * 80)\n",
    "        layouts_with_cq = []\n",
    "        for i, tree in enumerate(trees):\n",
    "            cq = self.calculate_cumulative_flow(tree)\n",
    "            length = sum(data['length'] for _, _, data in tree.edges(data=True))\n",
    "            layouts_with_cq.append((cq, tree, length))\n",
    "            print(f\"Layout {i+1}: CQ = {cq:.4f} mÂ³/s ({cq*1000:.2f} l/s), Length = {length:.2f} m\")\n",
    "        \n",
    "        # Step 3: Sort by CQ\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 3: Sorting Layouts by Cumulative Flow\")\n",
    "        print(\"=\" * 80)\n",
    "        layouts_with_cq.sort(key=lambda x: x[0])\n",
    "        \n",
    "        print(f\"\\nLayouts sorted (ascending CQ):\")\n",
    "        for i, (cq, _, length) in enumerate(layouts_with_cq[:10]):\n",
    "            print(f\"  Rank {i+1}: CQ = {cq:.4f} mÂ³/s ({cq*1000:.2f} l/s), Length = {length:.2f} m\")\n",
    "        \n",
    "        # Step 4: Optimize each layout with Modified PSO\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 4: Optimizing Component Sizes with Modified PSO\")\n",
    "        print(\"=\" * 80)\n",
    "        results = []\n",
    "        \n",
    "        for i, (cq, tree, length) in enumerate(layouts_with_cq):\n",
    "            print(f\"\\n--- Optimizing Layout {i+1}/{len(layouts_with_cq)} ---\")\n",
    "            print(f\"    CQ = {cq:.4f} mÂ³/s, Length = {length:.2f} m\")\n",
    "            cost, design_details = self._optimize_component_sizing(tree, pso_particles, pso_iterations)\n",
    "            results.append((i+1, cq, cost, tree, design_details))\n",
    "            print(f\"    Final Cost: Rs. {cost:,.2f}\")\n",
    "        \n",
    "        # Sort results by cost (lowest cost = best design)\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"STEP 5: Sorting Layouts by Total Cost\")\n",
    "        print(\"=\" * 80)\n",
    "        results.sort(key=lambda x: x[2])  # Sort by cost (index 2)\n",
    "        \n",
    "        print(\"\\nLayouts ranked by cost (Best = Minimum Cost):\")\n",
    "        for rank, (layout_num, cq, cost, _, _) in enumerate(results[:10], 1):\n",
    "            print(f\"  Rank {rank}: Layout {layout_num}, Cost = Rs. {cost:,.2f}, CQ = {cq:.4f} mÂ³/s\")\n",
    "        \n",
    "        # Store the best design details (minimum cost)\n",
    "        if results:\n",
    "            self.best_design_details = results[0][4]  # Details from best layout (lowest cost)\n",
    "            \n",
    "        return results\n",
    "    \n",
    "    def _optimize_component_sizing(self, tree: nx.Graph, \n",
    "                                   n_particles: int, \n",
    "                                   n_iterations: int) -> Tuple[float, Dict]:\n",
    "        \"\"\"Optimize component sizes for a given layout using Modified PSO\"\"\"\n",
    "        n_links = tree.number_of_edges()\n",
    "        \n",
    "        # Each link has 2 variables: diameter index and slope\n",
    "        n_dimensions = n_links * 2\n",
    "        \n",
    "        # Define bounds with extended diameter range\n",
    "        available_diameters = [0.2, 0.25, 0.3, 0.35, 0.4, 0.45, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 1.5]\n",
    "        bounds = []\n",
    "        for _ in range(n_links):\n",
    "            bounds.append((0, len(available_diameters) - 1))  # Diameter index\n",
    "            bounds.append((0.0004, 0.02))  # Slope range\n",
    "        \n",
    "        # Define cost function\n",
    "        def cost_function(x):\n",
    "            cost, _ = self._evaluate_design(tree, x, available_diameters)\n",
    "            return cost\n",
    "        \n",
    "        # Run PSO\n",
    "        pso = ModifiedPSO(n_particles, n_iterations, n_dimensions)\n",
    "        best_solution, best_cost = pso.optimize(cost_function, bounds)\n",
    "        \n",
    "        # Get detailed design for best solution\n",
    "        _, design_details = self._evaluate_design(tree, best_solution, available_diameters)\n",
    "        \n",
    "        return best_cost, design_details\n",
    "    \n",
    "    def _get_flow_direction_tree(self, tree: nx.Graph) -> nx.DiGraph:\n",
    "        \"\"\"Convert undirected tree to directed tree with flow from sources to outlet\"\"\"\n",
    "        # Create directed graph with flow towards outlet\n",
    "        directed_tree = nx.DiGraph()\n",
    "        directed_tree.add_nodes_from(tree.nodes(data=True))\n",
    "        \n",
    "        # BFS from outlet to determine flow direction\n",
    "        visited = set()\n",
    "        queue = [self.outlet_node]\n",
    "        visited.add(self.outlet_node)\n",
    "        parent = {self.outlet_node: None}\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            for neighbor in tree.neighbors(current):\n",
    "                if neighbor not in visited:\n",
    "                    # Flow goes FROM neighbor TO current (towards outlet)\n",
    "                    directed_tree.add_edge(neighbor, current, **tree[neighbor][current])\n",
    "                    parent[neighbor] = current\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append(neighbor)\n",
    "        \n",
    "        return directed_tree\n",
    "    \n",
    "    def _get_topological_order(self, directed_tree: nx.DiGraph) -> List[Tuple]:\n",
    "        \"\"\"Get edges in topological order (upstream to downstream)\"\"\"\n",
    "        # Find leaf nodes (sources - no incoming edges)\n",
    "        in_degree = {node: directed_tree.in_degree(node) for node in directed_tree.nodes()}\n",
    "        \n",
    "        # Start with nodes that have no predecessors (leaf nodes)\n",
    "        queue = [node for node, degree in in_degree.items() if degree == 0]\n",
    "        ordered_edges = []\n",
    "        \n",
    "        while queue:\n",
    "            current = queue.pop(0)\n",
    "            # Get all outgoing edges (downstream direction)\n",
    "            for successor in directed_tree.successors(current):\n",
    "                edge_data = directed_tree[current][successor]\n",
    "                ordered_edges.append((current, successor, edge_data))\n",
    "                \n",
    "                # Decrease in-degree and add to queue if all predecessors processed\n",
    "                in_degree[successor] -= 1\n",
    "                if in_degree[successor] == 0:\n",
    "                    queue.append(successor)\n",
    "        \n",
    "        return ordered_edges\n",
    "    \n",
    "    def _evaluate_design(self, tree: nx.Graph, design: np.ndarray, \n",
    "                        available_diameters: List[float]) -> Tuple[float, Dict]:\n",
    "        \"\"\"Evaluate total cost and constraints for a design\"\"\"\n",
    "        total_cost = 0.0\n",
    "        penalty = 0.0\n",
    "        design_details = []\n",
    "        \n",
    "        # Convert to directed tree for proper flow direction\n",
    "        directed_tree = self._get_flow_direction_tree(tree)\n",
    "        \n",
    "        # Get edges in topological order (upstream to downstream)\n",
    "        ordered_edges = self._get_topological_order(directed_tree)\n",
    "        \n",
    "        # Map to store diameter at each node for progressive diameter constraint\n",
    "        node_diameter = {}\n",
    "        \n",
    "        # Create edge index mapping\n",
    "        edge_to_index = {}\n",
    "        for i, (u, v, _) in enumerate(ordered_edges):\n",
    "            edge_to_index[(u, v)] = i\n",
    "        \n",
    "        for i, (u, v, data) in enumerate(ordered_edges):\n",
    "            # Extract design variables\n",
    "            d_idx = int(round(design[i * 2]))\n",
    "            d_idx = np.clip(d_idx, 0, len(available_diameters) - 1)\n",
    "            diameter = available_diameters[d_idx]\n",
    "            slope = design[i * 2 + 1]\n",
    "            \n",
    "            # Progressive diameter constraint (Eq. 11): D_current >= D_preceding\n",
    "            # For each upstream node feeding into current link, check its diameter\n",
    "            max_preceding_diameter = 0.0\n",
    "            upstream_nodes_with_diameter = []\n",
    "            \n",
    "            for pred in directed_tree.predecessors(u):\n",
    "                if pred in node_diameter:\n",
    "                    upstream_nodes_with_diameter.append((pred, node_diameter[pred]))\n",
    "                    max_preceding_diameter = max(max_preceding_diameter, node_diameter[pred])\n",
    "            \n",
    "            # Enforce progressive diameter constraint\n",
    "            if max_preceding_diameter > 0:\n",
    "                if diameter < max_preceding_diameter:\n",
    "                    # Must use at least the maximum preceding diameter\n",
    "                    diameter = max_preceding_diameter\n",
    "                    # Find closest available diameter that satisfies constraint\n",
    "                    valid_diameters = [d for d in available_diameters if d >= max_preceding_diameter]\n",
    "                    if valid_diameters:\n",
    "                        diameter = min(valid_diameters)\n",
    "            \n",
    "            # Store diameter at downstream node for this link\n",
    "            node_diameter[v] = diameter\n",
    "            \n",
    "            length = data['length']\n",
    "            flow = self._calculate_link_flow_directed(directed_tree, u, v)\n",
    "            \n",
    "            # Calculate hydraulics\n",
    "            params = self.hydraulics.calculate_flow_parameters(flow, diameter, slope)\n",
    "            \n",
    "            if params is None:\n",
    "                penalty += 1e8\n",
    "                # Store design even if invalid\n",
    "                design_details.append({\n",
    "                    'link': i + 1,\n",
    "                    'from_node': u,\n",
    "                    'to_node': v,\n",
    "                    'length': length,\n",
    "                    'diameter': diameter,\n",
    "                    'slope': slope,\n",
    "                    'slope_ratio': f\"1 in {int(1/slope) if slope > 0 else 'inf'}\",\n",
    "                    'flow': flow,\n",
    "                    'velocity': None,\n",
    "                    'd_D': None,\n",
    "                    'd': None,\n",
    "                    'status': 'Invalid - K >= 1/Ï€'\n",
    "                })\n",
    "                continue\n",
    "            \n",
    "            # Calculate costs\n",
    "            pipe_cost = self.cost_calc.get_pipe_cost(diameter, length)\n",
    "            \n",
    "            # Simplified depth calculation\n",
    "            avg_depth = 1.5  # Simplified\n",
    "            manhole_cost = self.cost_calc.get_manhole_cost(avg_depth)\n",
    "            earthwork_cost = self.cost_calc.get_earthwork_cost(avg_depth, length * 1.0)\n",
    "            \n",
    "            link_cost = pipe_cost + manhole_cost + earthwork_cost\n",
    "            total_cost += link_cost\n",
    "            \n",
    "            # Check constraints\n",
    "            V = params['V']\n",
    "            d_D = params['d_D']\n",
    "            d = params['d']\n",
    "            \n",
    "            # Track constraint violations\n",
    "            violations = []\n",
    "            \n",
    "            # Check progressive diameter constraint\n",
    "            if max_preceding_diameter > 0:\n",
    "                original_d_idx = int(round(design[i * 2]))\n",
    "                original_d_idx = np.clip(original_d_idx, 0, len(available_diameters) - 1)\n",
    "                original_diameter = available_diameters[original_d_idx]\n",
    "                \n",
    "                if original_diameter < max_preceding_diameter - 0.001:\n",
    "                    penalty += 1e6 * (max_preceding_diameter - original_diameter)\n",
    "                    violations.append(f\"D_prog: needed {diameter*1000:.0f}mm\")\n",
    "            \n",
    "            # Velocity constraints\n",
    "            if V < 0.6:\n",
    "                if flow >= 0.0014:  # As per paper\n",
    "                    penalty += 1e8 * (0.6 - V)\n",
    "                    violations.append(f\"V < 0.6 m/s\")\n",
    "            if V > 3.0:\n",
    "                penalty += 1e8 * (V - 3.0)\n",
    "                violations.append(f\"V > 3.0 m/s\")\n",
    "            \n",
    "            # Depth ratio constraint\n",
    "            if d_D > 0.8:\n",
    "                penalty += 1e8 * (d_D - 0.8)\n",
    "                violations.append(f\"d/D > 0.8\")\n",
    "            \n",
    "            # Cover depth (simplified check)\n",
    "            if avg_depth < 0.9:\n",
    "                penalty += 1e8 * (0.9 - avg_depth)\n",
    "                violations.append(f\"Cover < 0.9 m\")\n",
    "            if avg_depth > 5.0:\n",
    "                penalty += 1e8 * (avg_depth - 5.0)\n",
    "                violations.append(f\"Cover > 5.0 m\")\n",
    "            \n",
    "            # Store design details\n",
    "            design_details.append({\n",
    "                'link': i + 1,\n",
    "                'from_node': u,\n",
    "                'to_node': v,\n",
    "                'length': length,\n",
    "                'diameter': diameter,\n",
    "                'slope': slope,\n",
    "                'slope_ratio': f\"1 in {int(1/slope) if slope > 0 else 'inf'}\",\n",
    "                'flow': flow,\n",
    "                'flow_lps': flow * 1000,  # Convert to l/s\n",
    "                'velocity': V,\n",
    "                'd_D': d_D,\n",
    "                'd': d,\n",
    "                'link_cost': link_cost,\n",
    "                'status': 'OK' if not violations else ', '.join(violations),\n",
    "                'max_preceding_diameter': max_preceding_diameter if max_preceding_diameter > 0 else None\n",
    "            })\n",
    "        \n",
    "        return total_cost + penalty, design_details\n",
    "    \n",
    "    def _calculate_link_flow_directed(self, directed_tree: nx.DiGraph, u: int, v: int) -> float:\n",
    "        \"\"\"Calculate flow in a directed link by summing all upstream contributions\"\"\"\n",
    "        # Get all nodes upstream of u (including u itself)\n",
    "        upstream_nodes = set()\n",
    "        \n",
    "        def find_upstream(node):\n",
    "            upstream_nodes.add(node)\n",
    "            # Find all predecessors in directed tree\n",
    "            for pred in directed_tree.predecessors(node):\n",
    "                find_upstream(pred)\n",
    "        \n",
    "        find_upstream(u)\n",
    "        \n",
    "        # Sum all wastewater contributions from upstream nodes\n",
    "        total_flow = sum(self.nodes[node].wastewater_contribution \n",
    "                        for node in upstream_nodes \n",
    "                        if self.nodes[node].wastewater_contribution > 0)\n",
    "        \n",
    "        return total_flow / 1000  # Convert l/s to m3/s\n",
    "\n",
    "    def run_sensitivity_analysis(self, best_tree: nx.Graph, \n",
    "                                 swarm_sizes: List[int] = [200, 400, 600, 800, 1000],\n",
    "                                 iterations_list: List[int] = [30, 60, 90, 120]):\n",
    "        \"\"\"\n",
    "        Run sensitivity analysis for different swarm sizes and iterations\n",
    "        Returns results for plotting\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SENSITIVITY ANALYSIS: Swarm Size vs Cost\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        results = {}\n",
    "        total_runs = len(swarm_sizes) * len(iterations_list)\n",
    "        current_run = 0\n",
    "        \n",
    "        for iterations in iterations_list:\n",
    "            results[iterations] = {}\n",
    "            for swarm_size in swarm_sizes:\n",
    "                current_run += 1\n",
    "                print(f\"\\n[{current_run}/{total_runs}] Testing: Swarm={swarm_size}, Iterations={iterations}\")\n",
    "                \n",
    "                # Run optimization\n",
    "                cost, _ = self._optimize_component_sizing(best_tree, swarm_size, iterations)\n",
    "                results[iterations][swarm_size] = cost\n",
    "                \n",
    "                print(f\"    Result: Rs. {cost:,.2f}\")\n",
    "                \n",
    "                \n",
    "        \n",
    "        # Store in history\n",
    "        self.optimization_history = results\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    \n",
    "    def plot_sensitivity_analysis(self, results: Dict = None, save_path: str = 'output'):\n",
    "        \"\"\"\n",
    "        Plot swarm size vs cost for different iterations\n",
    "        \"\"\"\n",
    "        if results is None:\n",
    "            results = self.optimization_history\n",
    "        \n",
    "        if not results:\n",
    "            print(\"No results to plot. Run sensitivity analysis first.\")\n",
    "            return\n",
    "        \n",
    "        # Create figure with larger size\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Define colors and markers for different iterations\n",
    "        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728']\n",
    "        markers = ['o', 's', '^', 'D']\n",
    "        \n",
    "        # Extract data and plot\n",
    "        iterations_list = sorted(results.keys())\n",
    "        \n",
    "        for idx, iterations in enumerate(iterations_list):\n",
    "            swarm_sizes = sorted(results[iterations].keys())\n",
    "            costs = [results[iterations][size] for size in swarm_sizes]\n",
    "            \n",
    "            # Convert costs to millions for better readability\n",
    "            costs_millions = [c / 1e6 for c in costs]\n",
    "            \n",
    "            plt.plot(swarm_sizes, costs_millions, \n",
    "                    marker=markers[idx % len(markers)], \n",
    "                    color=colors[idx % len(colors)],\n",
    "                    linewidth=2, \n",
    "                    markersize=8,\n",
    "                    label=f'{iterations} Iterations')\n",
    "        \n",
    "        plt.xlabel('Swarm Size', fontsize=12, fontweight='bold')\n",
    "        plt.ylabel('Total Cost (Million Rs.)', fontsize=12, fontweight='bold')\n",
    "        plt.title('Sensitivity Analysis: Swarm Size vs Total Cost\\nat Different Iterations', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.legend(fontsize=10, loc='best')\n",
    "        plt.grid(True, alpha=0.3, linestyle='--')\n",
    "        plt.xticks(swarm_sizes if swarm_sizes else [200, 400, 600, 800, 1000])\n",
    "        \n",
    "        # Add minor gridlines\n",
    "        plt.minorticks_on()\n",
    "        plt.grid(which='minor', alpha=0.2, linestyle=':')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if save_path:\n",
    "            plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "            print(f\"\\nPlot saved to: {save_path}\")\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary table\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SENSITIVITY ANALYSIS RESULTS TABLE\")\n",
    "        print(\"=\" * 80)\n",
    "        print(f\"\\n{'Swarm Size':<12}\", end='')\n",
    "        for iterations in iterations_list:\n",
    "            print(f\"{'Iter=' + str(iterations):<20}\", end='')\n",
    "        print()\n",
    "        print(\"-\" * 80)\n",
    "        \n",
    "        if iterations_list and results[iterations_list[0]]:\n",
    "            swarm_sizes = sorted(results[iterations_list[0]].keys())\n",
    "            for swarm_size in swarm_sizes:\n",
    "                print(f\"{swarm_size:<12}\", end='')\n",
    "                for iterations in iterations_list:\n",
    "                    cost = results[iterations][swarm_size]\n",
    "                    print(f\"Rs. {cost:>15,.2f}   \", end='')\n",
    "                print()\n",
    "        \n",
    "        # Find best configuration\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"BEST CONFIGURATIONS\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        min_cost = float('inf')\n",
    "        best_config = None\n",
    "        \n",
    "        for iterations in iterations_list:\n",
    "            for swarm_size, cost in results[iterations].items():\n",
    "                if cost < min_cost:\n",
    "                    min_cost = cost\n",
    "                    best_config = (swarm_size, iterations)\n",
    "        \n",
    "        if best_config:\n",
    "            print(f\"\\nâ˜… Overall Best: Swarm Size = {best_config[0]}, Iterations = {best_config[1]}\")\n",
    "            print(f\"  Minimum Cost: Rs. {min_cost:,.2f}\")\n",
    "            \n",
    "        # Best for each iteration level\n",
    "        print(\"\\nðŸ“Š Best Swarm Size for Each Iteration Level:\")\n",
    "        for iterations in iterations_list:\n",
    "            costs = results[iterations]\n",
    "            best_swarm = min(costs, key=costs.get)\n",
    "            best_cost = costs[best_swarm]\n",
    "            print(f\"  {iterations} Iterations: Swarm = {best_swarm}, Cost = Rs. {best_cost:,.2f}\")\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "def parse_sewer_file(filepath):\n",
    "    \"\"\"\n",
    "    Parse the same file format as CedritosNorte.txt\n",
    "    Returns:\n",
    "        nodes_df: DataFrame with columns ['id','flow','x','y','elevation']\n",
    "        edges_df: DataFrame with columns ['u','v']\n",
    "    \"\"\"\n",
    "    with open(filepath, \"r\") as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "    # find \"Manholes\" line index\n",
    "    idx = 0\n",
    "    if not lines[0].lower().startswith(\"manholes\"):\n",
    "        raise ValueError(\"File must start with 'Manholes <count>'\")\n",
    "    manholes_count = int(lines[0].split()[1])\n",
    "    manhole_lines = lines[1: 1 + manholes_count]\n",
    "\n",
    "    nodes = []\n",
    "    for ln in manhole_lines:\n",
    "        parts = ln.split()\n",
    "        if len(parts) < 5:\n",
    "            raise ValueError(\"Expected 5 columns in manholes rows\")\n",
    "        nid = int(parts[0])\n",
    "        flow = float(parts[1])\n",
    "        x = float(parts[2])\n",
    "        y = float(parts[3])\n",
    "        elev = float(parts[4])\n",
    "        nodes.append((nid, flow, x, y, elev))\n",
    "    nodes_df = pd.DataFrame(nodes, columns=[\"id\", \"flow\", \"x\", \"y\", \"elevation\"]).set_index(\"id\")\n",
    "\n",
    "    # next line after manholes block should be \"Sections <count>\"\n",
    "    sec_line_idx = 1 + manholes_count\n",
    "    if not lines[sec_line_idx].lower().startswith(\"sections\"):\n",
    "        raise ValueError(\"Expected 'Sections <count>' after Manholes block\")\n",
    "    sec_count = int(lines[sec_line_idx].split()[1])\n",
    "    section_lines = lines[sec_line_idx + 1: sec_line_idx + 1 + sec_count]\n",
    "\n",
    "    edges = []\n",
    "    for ln in section_lines:\n",
    "        parts = ln.split()\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        u, v = int(parts[0]), int(parts[1])\n",
    "        edges.append((u, v))\n",
    "    edges_df = pd.DataFrame(edges, columns=[\"u\", \"v\"])\n",
    "    return nodes_df, edges_df\n",
    "\n",
    "\n",
    "\n",
    "def build_weighted_graph(nodes_df, edges_df):\n",
    "    \"\"\"\n",
    "    Build an undirected graph with Euclidean distance weights between node coords.\n",
    "    Returns networkx.Graph() and a pos dict {node: (x,y)} for plotting.\n",
    "    nodes_df: index = node id, columns include ['x','y','flow','elevation'] (flow/elevation optional)\n",
    "    edges_df: two columns (u,v) or index can be ignored; each row is (u,v)\n",
    "    \"\"\"\n",
    "    G = nx.Graph()\n",
    "    outlet_id=None\n",
    "    \n",
    "    # Add nodes with attributes and build pos dict\n",
    "    for nid, row in nodes_df.iterrows():\n",
    "\n",
    "        x = float(row[\"x\"])\n",
    "        y = float(row[\"y\"])\n",
    "        # safe-get flow and elevation (set to 0 if missing)\n",
    "        flow = float(row[\"flow\"]) if \"flow\" in row and not pd.isna(row[\"flow\"]) else 0.0\n",
    "        #print(flow)\n",
    "        \n",
    "        #outlet node\n",
    "        if(flow<0):\n",
    "            outlet_id=nid\n",
    "            \n",
    "        elev = float(row[\"elevation\"]) if \"elevation\" in row and not pd.isna(row[\"elevation\"]) else None\n",
    "        G.add_node(nid, x=x, y=y, ground_level=elev,flow=flow)\n",
    "\n",
    "    # Add edges with length weight\n",
    "    for _, (u, v) in edges_df.iterrows():\n",
    "        if u not in nodes_df.index or v not in nodes_df.index:\n",
    "            continue\n",
    "        xu, yu = nodes_df.loc[u, [\"x\", \"y\"]]\n",
    "        xv, yv = nodes_df.loc[v, [\"x\", \"y\"]]\n",
    "        length = math.hypot(float(xu) - float(xv), float(yu) - float(yv))\n",
    "        G.add_edge(u, v, length=length)\n",
    "        \n",
    "            \n",
    "    print(f\"\\nTree Network Summary:\")\n",
    "    print(f\"=\"*20)\n",
    "    print(f\"Total Manholes: {G.number_of_nodes()}\")\n",
    "    print(f\"Total Sections: {G.number_of_edges()}\")\n",
    "    print(f\"Outlet Node: {outlet_id}\")\n",
    "\n",
    "        \n",
    "\n",
    "    return G,outlet_id\n",
    "\n",
    "import os, csv\n",
    "\n",
    "def safe_float(value, decimals=None):\n",
    "    if value is None or value == \"\":\n",
    "        return \"\"\n",
    "    try:\n",
    "        v = float(value)\n",
    "        return round(v, decimals) if decimals is not None else v\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "import os, csv\n",
    "\n",
    "\n",
    "def safe_float(value, decimals=None):\n",
    "    if value is None or value == \"\":\n",
    "        return \"\"\n",
    "    try:\n",
    "        v = float(value)\n",
    "        return round(v, decimals) if decimals is not None else v\n",
    "    except:\n",
    "        return \"\"\n",
    "\n",
    "def save_results_with_input_details(\n",
    "    Input_file: str,\n",
    "    nodes_df,\n",
    "    nodes_data: dict,\n",
    "    best_details: list,\n",
    "    output_dir: str = \"output\"\n",
    "):\n",
    "    base_name = os.path.splitext(os.path.basename(Input_file))[0]\n",
    "    output_file = os.path.join(output_dir, f\"{base_name}_results.csv\")\n",
    "\n",
    "    required_cols = [\"x\", \"y\", \"elevation\", \"flow\"]\n",
    "    for col in required_cols:\n",
    "        if col not in nodes_df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found in nodes_df\")\n",
    "\n",
    "    fieldnames = [\n",
    "        'link', 'from_node', 'to_node', 'length', 'diameter', 'slope', 'slope_ratio',\n",
    "        'flow_lps', 'velocity', 'd_D', 'd', 'status', 'max_preceding_diameter',\n",
    "        'input_flow_lps', 'x', 'y', 'z'\n",
    "    ]\n",
    "\n",
    "    with open(output_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for detail in best_details:\n",
    "            from_node = detail.get('from_node')\n",
    "            node_info = nodes_df.loc[from_node] if from_node in nodes_df.index else None\n",
    "\n",
    "            input_flow = x = y = z = \"\"\n",
    "            if node_info is not None:\n",
    "                input_flow = safe_float(node_info['flow'] * 1000, 3)\n",
    "                x = safe_float(node_info['x'])\n",
    "                y = safe_float(node_info['y'])\n",
    "                z = safe_float(node_info['elevation'])\n",
    "\n",
    "            flow_lps = detail.get('flow_lps')\n",
    "            if flow_lps is None and 'flow' in detail:\n",
    "                flow_lps = detail['flow'] * 1000\n",
    "\n",
    "            writer.writerow({\n",
    "                'link': detail.get('link', ''),\n",
    "                'from_node': from_node,\n",
    "                'to_node': detail.get('to_node', ''),\n",
    "                'input_flow_lps': input_flow,\n",
    "                'x': x,\n",
    "                'y': y,\n",
    "                'z': z,\n",
    "                'length': safe_float(detail.get('length'), 2),\n",
    "                'diameter': detail.get('diameter', ''),\n",
    "                'slope': safe_float(detail.get('slope'), 2),\n",
    "                'slope_ratio': detail.get('slope_ratio', ''),\n",
    "                'flow_lps': safe_float(flow_lps, 3),\n",
    "                'velocity': safe_float(detail.get('velocity'), 2),\n",
    "                'd_D': safe_float(detail.get('d_D'), 3),\n",
    "                'd': safe_float(detail.get('d'), 3),\n",
    "                'status': detail.get('status', ''),\n",
    "                'max_preceding_diameter': detail.get('max_preceding_diameter', '')\n",
    "            })\n",
    "\n",
    "    print(f\"âœ… Results with input details saved to: {output_file}\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "\n",
    "def plot_graph_with_coords(G, title=\"Tree Plot\", show_elevation=False, show_lengths=True, \n",
    "                          show_edge_flows=False, figsize=(10, 8), save_path=None):\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    ax = plt.gca()\n",
    "    \n",
    "    # extract positions of manholes\n",
    "    pos = {}\n",
    "    for n, data in G.nodes(data=True):\n",
    "        if \"x\" in data and \"y\" in data:\n",
    "            pos[n] = (float(data[\"x\"]), float(data[\"y\"]))\n",
    "    \n",
    "    # Node sizes: scale flow (add small base so zero-flow nodes are visible)\n",
    "    flows = nx.get_node_attributes(G, \"flow\")\n",
    "    \n",
    "    # Edge widths: normalize lengths to a reasonable thickness\n",
    "    lengths = nx.get_edge_attributes(G, \"length\")\n",
    "    edge_flows = nx.get_edge_attributes(G, \"flow_m3s\")\n",
    "    \n",
    "    # Draw edges and nodes at their coordinates\n",
    "    nx.draw_networkx_edges(G, pos, ax=ax, width=2)\n",
    "    node_collection = nx.draw_networkx_nodes(G, pos, node_size=500, ax=ax)\n",
    "    nx.draw_networkx_labels(G, pos, font_size=9, ax=ax)\n",
    "    \n",
    "    edge_labels = {}\n",
    "    for e, d in G.edges.items():\n",
    "        text = []\n",
    "        if show_lengths and \"length\" in d:\n",
    "            text.append(f\"L={d['length']:.2f} m\")\n",
    "        if show_edge_flows and \"flow_m3s\" in d:\n",
    "            text.append(f\"Q={d['flow_m3s']:.3f} m3/s\")\n",
    "        if text:\n",
    "            edge_labels[e] = \"\\n\".join(text)  # stacked\n",
    "            \n",
    "    if edge_labels:\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels, font_size=8, label_pos=0.5)\n",
    "    \n",
    "    # Optional: annotate elevation next to nodes\n",
    "    if show_elevation:\n",
    "        elevs = nx.get_node_attributes(G, \"elevation\")\n",
    "        for n, (x, y) in pos.items():\n",
    "            ev = elevs.get(n, None)\n",
    "            if ev is not None:\n",
    "                ax.text(x + 0.2, y + 0.2, f\"{ev:.2f}m\", fontsize=7, alpha=0.8)\n",
    "    \n",
    "    ax.set_aspect('equal', adjustable='datalim')   # preserve scale\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure if path is provided\n",
    "    save_path=\"output/result_layout.png\"\n",
    "    if save_path:\n",
    "        plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"Figure saved to: {save_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    \n",
    "def _split_cols(line: str):\n",
    "    \"\"\"Split a line by whitespace/tabs but preserve negative signs and decimals.\"\"\"\n",
    "    return re.split(r'\\s+', line.strip())\n",
    "\n",
    "def parse_sewer_file_1(filepath: str):\n",
    "    \"\"\"\n",
    "    Parse a sewer network .txt file in the 'CedritosNorte' or 'Li' format.\n",
    "\n",
    "    Returns:\n",
    "        nodes_df: DataFrame indexed by 'id' with columns ['flow','x','y','elevation']\n",
    "        edges_df: DataFrame with columns ['u','v']\n",
    "    \"\"\"\n",
    "    with open(filepath, 'r', encoding='utf-8') as f:\n",
    "        lines = [ln.strip() for ln in f if ln.strip()]\n",
    "\n",
    "    # ---- MANHOLES BLOCK ----\n",
    "    idx = 0\n",
    "    while idx < len(lines) and not lines[idx].lower().startswith(\"manholes\"):\n",
    "        idx += 1\n",
    "    if idx >= len(lines):\n",
    "        raise ValueError(\"File must start with 'Manholes <count>'\")\n",
    "    manholes_count = int(_split_cols(lines[idx])[1])\n",
    "\n",
    "    # detect header row (like: ID X Y Z INFLOW)\n",
    "    manhole_start = idx + 1\n",
    "    if re.search(r'[A-Za-z]', lines[manhole_start]):\n",
    "        manhole_lines = lines[manhole_start + 1: manhole_start + 1 + manholes_count]\n",
    "    else:\n",
    "        manhole_lines = lines[manhole_start: manhole_start + manholes_count]\n",
    "\n",
    "    nodes = []\n",
    "    for ln in manhole_lines:\n",
    "        parts = _split_cols(ln)\n",
    "        if len(parts) < 5:\n",
    "            continue\n",
    "        nid = int(parts[0])\n",
    "        x = float(parts[1])\n",
    "        y = float(parts[2])\n",
    "        elev = float(parts[3])\n",
    "        flow = float(parts[4])\n",
    "        nodes.append((nid, flow, x, y, elev))\n",
    "\n",
    "    nodes_df = pd.DataFrame(nodes, columns=[\"id\", \"flow\", \"x\", \"y\", \"elevation\"]).set_index(\"id\")\n",
    "\n",
    "    # ---- SECTIONS BLOCK ----\n",
    "    sec_line_idx = manhole_start + 1 + manholes_count\n",
    "    while sec_line_idx < len(lines) and not lines[sec_line_idx].lower().startswith(\"sections\"):\n",
    "        sec_line_idx += 1\n",
    "    if sec_line_idx >= len(lines):\n",
    "        raise ValueError(\"Could not find 'Sections' block\")\n",
    "\n",
    "    sec_count = int(_split_cols(lines[sec_line_idx])[1])\n",
    "\n",
    "    # detect section header like \"v1 v2 slope intercept\"\n",
    "    section_start = sec_line_idx + 1\n",
    "    if re.search(r'[A-Za-z]', lines[section_start]):\n",
    "        section_lines = lines[section_start + 1: section_start + 1 + sec_count]\n",
    "    else:\n",
    "        section_lines = lines[section_start: section_start + sec_count]\n",
    "\n",
    "    edges = []\n",
    "    for ln in section_lines:\n",
    "        parts = _split_cols(ln)\n",
    "        if len(parts) < 2:\n",
    "            continue\n",
    "        u, v = int(parts[0]), int(parts[1])\n",
    "        edges.append((u, v))\n",
    "\n",
    "    edges_df = pd.DataFrame(edges, columns=[\"u\", \"v\"])\n",
    "\n",
    "    return nodes_df, edges_df\n",
    "\n",
    "def get_pso_settings():\n",
    "    while True:\n",
    "        default = input(\"Use default settings (Y/N): \").strip().upper()\n",
    "\n",
    "        if default == \"N\":\n",
    "            try:\n",
    "                n_layouts = int(input(\"Enter number of top layouts: \"))\n",
    "                pso_particles = int(input(\"Enter number of PSO particles: \"))\n",
    "                pso_iterations = int(input(\"Enter Max Iterations: \"))\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"âš ï¸ Invalid input! Please enter numeric values.\\n\")\n",
    "        \n",
    "        elif default == \"Y\":\n",
    "            n_layouts = 8\n",
    "            pso_particles = 10\n",
    "            pso_iterations = 10\n",
    "            break\n",
    "        \n",
    "        else:\n",
    "            print(\"âš ï¸ Please enter only Y or N.\\n\")\n",
    "\n",
    "    print(\"\\nâœ… Settings Applied Successfully:\")\n",
    "    print(f\"Top Layouts     : {n_layouts}\")\n",
    "    print(f\"PSO Particles   : {pso_particles}\")\n",
    "    print(f\"Max Iterations  : {pso_iterations}\")\n",
    "    \n",
    "    return n_layouts, pso_particles, pso_iterations\n",
    "\n",
    "def ask_and_run_sensitivity(best_tree):\n",
    "    run_choice = input(\"Do you want to run Sensitivity Analysis? (Y/N): \").strip().upper()\n",
    "\n",
    "    if run_choice == \"N\":\n",
    "        print(\"\\nâ­ï¸ Sensitivity analysis skipped.\")\n",
    "        return None\n",
    "\n",
    "    elif run_choice == \"Y\":\n",
    "        # Ask for default/custom settings\n",
    "        default = input(\"Use default sensitivity settings? (Y/N): \").strip().upper()\n",
    "\n",
    "        if default == \"N\":\n",
    "            try:\n",
    "                swarm_sizes = list(map(int, input(\"Enter swarm sizes (comma-separated): \").split(\",\")))\n",
    "                iterations_list = list(map(int, input(\"Enter iteration list (comma-separated): \").split(\",\")))\n",
    "            except ValueError:\n",
    "                print(\"âš ï¸ Invalid input! Using default values instead.\")\n",
    "                swarm_sizes = [200, 400, 600, 800, 1000]\n",
    "                iterations_list = [30, 60, 90, 120]\n",
    "        else:\n",
    "            swarm_sizes = [200, 400, 600, 800, 1000]\n",
    "            iterations_list = [30, 60, 90, 120]\n",
    "\n",
    "        print(\"\\nâš™ï¸ Running Sensitivity Analysis with settings:\")\n",
    "        print(f\"Swarm Sizes      : {swarm_sizes}\")\n",
    "        print(f\"Iteration Counts : {iterations_list}\\n\")\n",
    "\n",
    "        sensitivity_results = optimizer.run_sensitivity_analysis(\n",
    "            best_tree,\n",
    "            swarm_sizes=swarm_sizes,\n",
    "            iterations_list=iterations_list\n",
    "        )\n",
    "        \n",
    "        \n",
    "        \n",
    "        # Plot results\n",
    "        print(\"\\nGenerating sensitivity analysis plot...\")\n",
    "        optimizer.plot_sensitivity_analysis(sensitivity_results, save_path='output/sensitivity_analysis.png')\n",
    "        print(\"DETAILED OPTIMAL DESIGN - BEST LAYOUT (Minimum Cost)\")\n",
    "        print(\"=\" * 120)\n",
    "\n",
    "        print(\"âœ… Sensitivity Analysis Completed Successfully!\")\n",
    "        return 0\n",
    "\n",
    "    else:\n",
    "        print(\"âš ï¸ Please enter only Y or N.\\n\")\n",
    "        return ask_and_run_sensitivity( best_tree)  # re-ask if invalid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b06f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    " \n",
    "    #=====================Input File and parameter selection========================================\n",
    "    \n",
    "    Input_file='input/LiMathew_Revised.txt'\n",
    "    \n",
    "    Name=str(Input_file)\n",
    "    \n",
    "    nodes_df,edges_df=parse_sewer_file_1(Input_file) # Parse the input file\n",
    "    \n",
    "    n_layouts, pso_particles, pso_iterations= get_pso_settings() # get the input parameters\n",
    "    \n",
    "\n",
    "    #======================================Start of optimisation======================================\n",
    "    \n",
    "    #Graph Building\n",
    "    G,outlet_id=build_weighted_graph(nodes_df,edges_df)\n",
    "    \n",
    "    nodes_data = {}\n",
    "    for nid, row in nodes_df.iterrows():\n",
    "        nodes_data[nid]=Node(id=nid,\n",
    "        wastewater_contribution=round(float(row['flow']*1000),3),\n",
    "        ground_level=float(row[\"elevation\"])\n",
    "                            )\n",
    "        \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"SEWER NETWORK OPTIMIZATION - {len(nodes_df)} MANHOLE NETWORK\")\n",
    "    print(\"=\" * 80)\n",
    "                             \n",
    "    #Flow calculations \n",
    "    total_inflow = sum(n.wastewater_contribution for n in nodes_data.values() if n.wastewater_contribution > 0)\n",
    "    outlet_flow = abs(nodes_data[outlet_id].wastewater_contribution)\n",
    "    print(f\"  Total Inflow: {total_inflow:.2f} l/s ({total_inflow/1000:.4f} mÂ³/s)\")\n",
    "    print(f\"  Outlet Flow: {outlet_flow:.2f} l/s ({outlet_flow/1000:.4f} mÂ³/s)\")\n",
    "    \n",
    "    # Check flow balance\n",
    "    print(f\"  Flow Balance: {'âœ“ OK' if abs(total_inflow - outlet_flow) < 1 else 'âœ— Imbalanced'}\")\n",
    "    \n",
    "    # Create optimizer\n",
    "    optimizer = SewerNetworkOptimizer(G, nodes_data, outlet_id)\n",
    "    \n",
    "    # Run optimization with reasonable parameters for this size network\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"Starting Optimization Process for {Name}...\")\n",
    "    print(\"=\" * 80)\n",
    "             \n",
    "        \n",
    "        \n",
    "        \n",
    "   #===================================Algorithm============================================\n",
    "\n",
    "    results = optimizer.optimize_layout_sequence(\n",
    "        n_layouts, \n",
    "        pso_particles,\n",
    "        pso_iterations\n",
    "    )\n",
    "    \n",
    "    #========================================================================================\n",
    "\n",
    "    \n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"OPTIMIZATION RESULTS - ALL LAYOUTS\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"\\n{'Rank':<6} {'Layout':<8} {'CQ (mÂ³/s)':<12} {'CQ (l/s)':<12} {'Total Cost (Rs.)':<20}\")\n",
    "    print(\"-\" * 65)\n",
    "    for rank, (layout_num, cq, cost, _, _) in enumerate(results[:10], 1):\n",
    "        marker = \"â˜… BEST\" if rank == 1 else \"\"\n",
    "        print(f\"{rank:<6} {layout_num:<8} {cq:<12.4f} {cq*1000:<12.2f} {cost:>18,.2f}  {marker}\")\n",
    "\n",
    "    # Display detailed design for best layout (minimum cost)\n",
    "    if results:\n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 80)\n",
    "        print(\"SENSITIVITY ANALYSIS OPTION\")\n",
    "        print(\"=\" * 80)\n",
    "        print(\"(This will test different swarm sizes and iterations)\")\n",
    "        print(\"Note: This may take significant time depending on network size\")\n",
    "\n",
    "        # For demonstration, we'll run a quick sensitivity analysis on best layout\n",
    "        print(\"\\nRunning sensitivity analysis on best layout...\")\n",
    "\n",
    "        # Get best layout tree\n",
    "        best_tree = results[0][3]\n",
    "\n",
    "        #Run sensitivity analysis with configurable parameters\n",
    "#         sensitivity_results = optimizer.run_sensitivity_analysis(\n",
    "#             best_tree,\n",
    "#             swarm_sizes=[200, 400, 600, 800, 1000],\n",
    "#             iterations_list=[30, 60, 90, 120]\n",
    "#         )\n",
    "\n",
    "#         # Plot results\n",
    "#         print(\"\\nGenerating sensitivity analysis plot...\")\n",
    "#         optimizer.plot_sensitivity_analysis(sensitivity_results, save_path='sensitivity_analysis.png')\n",
    "#         print(\"DETAILED OPTIMAL DESIGN - BEST LAYOUT (Minimum Cost)\")\n",
    "#         print(\"=\" * 120)\n",
    "\n",
    "        best_layout_num, best_cq, best_cost, _, best_details = results[0]\n",
    "    \n",
    "    \n",
    "    \n",
    "        #save csv file\n",
    "        \n",
    "        save_results_with_input_details(Input_file, nodes_df, nodes_data, best_details)\n",
    "\n",
    "        print(f\"\\nâœ“ Best Layout: #{best_layout_num}\")\n",
    "        print(f\"âœ“ Total Cumulative Flow (CQ): {best_cq:.4f} mÂ³/s ({best_cq*1000:.2f} l/s)\")\n",
    "        print(f\"âœ“ TOTAL NETWORK COST: Rs. {best_cost:,.2f} â˜… MINIMUM â˜…\")\n",
    "        print(f\"âœ“ Number of Sewer Sections: {len(best_details)}\")\n",
    "\n",
    "        # Print header\n",
    "        print(f\"\\n{'Pipe':<6} {'From':<6} {'To':<6} {'Length':<9} {'Diameter':<10} {'Slope':<14} \"\n",
    "              f\"{'Flow':<11} {'Velocity':<10} {'d/D':<8} {'d (m)':<8} {'Prev D':<10} {'Status':<25}\")\n",
    "        print(f\"{'No.':<6} {'Node':<6} {'Node':<6} {'(m)':<9} {'(mm)':<10} {'(1 in X)':<14} \"\n",
    "              f\"{'(l/s)':<11} {'(m/s)':<10} {'':<8} {'':<8} {'(mm)':<10} {'':<25}\")\n",
    "        print(\"-\" * 140)\n",
    "\n",
    "        # Print each link\n",
    "        total_length = 0\n",
    "        valid_links = 0\n",
    "        progressive_violations = 0\n",
    "\n",
    "        for detail in best_details:\n",
    "            link = detail['link']\n",
    "            from_node = detail['from_node']\n",
    "            to_node = detail['to_node']\n",
    "            length = detail['length']\n",
    "            diameter = detail['diameter']\n",
    "            slope = detail['slope']\n",
    "            slope_ratio = detail['slope_ratio']\n",
    "            flow_lps = detail.get('flow_lps', detail['flow'] * 1000)\n",
    "            velocity = detail['velocity']\n",
    "            d_D = detail['d_D']\n",
    "            d = detail['d']\n",
    "            status = detail['status']\n",
    "            max_preceding_diameter = detail.get('max_preceding_diameter', None)\n",
    "\n",
    "            total_length += length\n",
    "            if status == 'OK':\n",
    "                valid_links += 1\n",
    "\n",
    "            if 'D_prog' in status:\n",
    "                progressive_violations += 1\n",
    "\n",
    "            # Format values\n",
    "            diameter_mm = diameter * 1000\n",
    "            vel_str = f\"{velocity:.3f}\" if velocity is not None else \"N/A\"\n",
    "            d_D_str = f\"{d_D:.4f}\" if d_D is not None else \"N/A\"\n",
    "            d_str = f\"{d:.4f}\" if d is not None else \"N/A\"\n",
    "            prev_d_str = f\"{max_preceding_diameter*1000:.0f}\" if max_preceding_diameter else \"-\"\n",
    "\n",
    "            # Color code status\n",
    "            status_display = status if len(status) <= 25 else status[:22] + \"...\"\n",
    "\n",
    "            print(f\"{link:<6} {from_node:<6} {to_node:<6} {length:<9.2f} {diameter_mm:<10.0f} \"\n",
    "                  f\"{slope_ratio:<14} {flow_lps:<11.3f} {vel_str:<10} {d_D_str:<8} \"\n",
    "                  f\"{d_str:<8} {prev_d_str:<10} {status_display:<25}\")\n",
    "            \n",
    "        # plot the graph \n",
    "        plot_graph_with_coords(best_tree,\"output_graph\",show_lengths=False,show_elevation=False)\n",
    "\n",
    "        print(\"-\" * 140)\n",
    "        print(f\"Total Network Length: {total_length:.2f} m\")\n",
    "        print(f\"Valid Links (All constraints satisfied): {valid_links}/{len(best_details)}\")\n",
    "        if progressive_violations > 0:\n",
    "            print(f\"âš  Progressive Diameter Violations: {progressive_violations}\")\n",
    "\n",
    "        # Detailed statistics\n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "        print(\"DESIGN STATISTICS AND CONSTRAINT VERIFICATION\")\n",
    "        print(\"=\" * 120)\n",
    "\n",
    "        velocities = [d['velocity'] for d in best_details if d['velocity'] is not None]\n",
    "        d_D_ratios = [d['d_D'] for d in best_details if d['d_D'] is not None]\n",
    "        diameters = [d['diameter'] * 1000 for d in best_details]\n",
    "        flows = [d.get('flow_lps', d['flow'] * 1000) for d in best_details]\n",
    "\n",
    "        print(\"\\nðŸ“Š HYDRAULIC PARAMETERS:\")\n",
    "        if velocities:\n",
    "            print(f\"  Velocity Statistics:\")\n",
    "            print(f\"    â€¢ Minimum: {min(velocities):.3f} m/s\")\n",
    "            print(f\"    â€¢ Maximum: {max(velocities):.3f} m/s\")\n",
    "            print(f\"    â€¢ Average: {np.mean(velocities):.3f} m/s\")\n",
    "            print(f\"    â€¢ Std Dev: {np.std(velocities):.3f} m/s\")\n",
    "\n",
    "            below_min = sum(1 for v in velocities if v < 0.6)\n",
    "            above_max = sum(1 for v in velocities if v > 3.0)\n",
    "            print(f\"    â€¢ Links below 0.6 m/s: {below_min}\")\n",
    "            print(f\"    â€¢ Links above 3.0 m/s: {above_max}\")\n",
    "\n",
    "        if d_D_ratios:\n",
    "            print(f\"\\n  d/D Ratio Statistics:\")\n",
    "            print(f\"    â€¢ Minimum: {min(d_D_ratios):.4f}\")\n",
    "            print(f\"    â€¢ Maximum: {max(d_D_ratios):.4f}\")\n",
    "            print(f\"    â€¢ Average: {np.mean(d_D_ratios):.4f}\")\n",
    "            above_08 = sum(1 for r in d_D_ratios if r > 0.8)\n",
    "            print(f\"    â€¢ Links above 0.8: {above_08}\")\n",
    "\n",
    "        print(f\"\\n  Diameter Distribution:\")\n",
    "        unique_diameters = sorted(set(diameters))\n",
    "        for d in unique_diameters:\n",
    "            count = sum(1 for dia in diameters if dia == d)\n",
    "            print(f\"    â€¢ {d:.0f} mm: {count} links\")\n",
    "\n",
    "        print(f\"\\n  Flow Statistics:\")\n",
    "        print(f\"    â€¢ Minimum: {min(flows):.3f} l/s\")\n",
    "        print(f\"    â€¢ Maximum: {max(flows):.3f} l/s\")\n",
    "        print(f\"    â€¢ Average: {np.mean(flows):.3f} l/s\")\n",
    "\n",
    "        print(\"\\nâœ“ CONSTRAINT LIMITS:\")\n",
    "        print(\"    â€¢ Velocity: 0.6 - 3.0 m/s\")\n",
    "        print(\"    â€¢ d/D ratio: â‰¤ 0.8\")\n",
    "        print(\"    â€¢ Min diameter: 200 mm\")\n",
    "        print(\"    â€¢ Cover depth: 0.9 - 5.0 m\")\n",
    "        print(\"    â€¢ Progressive diameter: D_current â‰¥ D_preceding (Eq. 11) - ENFORCED BY SELECTION\")\n",
    "\n",
    "        # Check if any diameters were increased to satisfy progressive constraint\n",
    "        enforced_increases = [d for d in best_details if d.get('enforced_increase', False)]\n",
    "        if enforced_increases:\n",
    "            print(f\"\\nâš™ Progressive Diameter Adjustments:\")\n",
    "            print(f\"    â€¢ {len(enforced_increases)} pipe(s) had diameter increased to satisfy Eq. 11\")\n",
    "            for detail in enforced_increases[:5]:  # Show first 5\n",
    "                link = detail['link']\n",
    "                proposed = detail.get('proposed_diameter', 0) * 1000\n",
    "                actual = detail['diameter'] * 1000\n",
    "                print(f\"      Link {link}: {proposed:.0f}mm â†’ {actual:.0f}mm\")\n",
    "\n",
    "        # Cost breakdown\n",
    "        print(\"\\nðŸ’° COST SUMMARY:\")\n",
    "        print(f\"    â€¢ Total Network Cost: Rs. {best_cost:,.2f}\")\n",
    "        print(f\"    â€¢ Cost per meter: Rs. {best_cost/total_length:,.2f}/m\")\n",
    "\n",
    "        print(\"\\n\" + \"=\" * 120)\n",
    "        \n",
    "        \n",
    "        \n",
    "        #============================================RUN SESITIVITY ANALYSIS=============================================\n",
    "        \n",
    "        sensitivity_results = ask_and_run_sensitivity(best_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f375950",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d911dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
